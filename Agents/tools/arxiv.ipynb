{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arxiv\n",
    "* https://python.langchain.com/en/latest/modules/agents/tools/examples/arxiv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install arxiv\n",
    "!pip install langchain==0.0.145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2017-07-18\\nTitle: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\\nAuthors: Chelsea Finn, Pieter Abbeel, Sergey Levine\\nSummary: We propose an algorithm for meta-learning that is model-agnostic, in the\\nsense that it is compatible with any model trained with gradient descent and\\napplicable to a variety of different learning problems, including\\nclassification, regression, and reinforcement learning. The goal of\\nmeta-learning is to train a model on a variety of learning tasks, such that it\\ncan solve new learning tasks using only a small number of training samples. In\\nour approach, the parameters of the model are explicitly trained such that a\\nsmall number of gradient steps with a small amount of training data from a new\\ntask will produce good generalization performance on that task. In effect, our\\nmethod trains the model to be easy to fine-tune. We demonstrate that this\\napproach leads to state-of-the-art performance on two few-shot image\\nclassification benchmarks, produces good results on few-shot regression, and\\naccelerates fine-tuning for policy gradient reinforcement learning with neural\\nnetwork policies.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv = ArxivAPIWrapper()\n",
    "\n",
    "docs = arxiv.run(\"1703.03400\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2015-04-10\\nTitle: Learning Compact Convolutional Neural Networks with Nested Dropout\\nAuthors: Chelsea Finn, Lisa Anne Hendricks, Trevor Darrell\\nSummary: Recently, nested dropout was proposed as a method for ordering representation\\nunits in autoencoders by their information content, without diminishing\\nreconstruction cost. However, it has only been applied to training\\nfully-connected autoencoders in an unsupervised setting. We explore the impact\\nof nested dropout on the convolutional layers in a CNN trained by\\nbackpropagation, investigating whether nested dropout can provide a simple and\\nsystematic way to determine the optimal representation size with respect to the\\ndesired accuracy and desired task and data complexity.\\n\\nPublished: 2016-05-27\\nTitle: Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization\\nAuthors: Chelsea Finn, Sergey Levine, Pieter Abbeel\\nSummary: Reinforcement learning can acquire complex behaviors from high-level\\nspecifications. However, defining a cost function that can be optimized\\neffectively and encodes the correct task is challenging in practice. We explore\\nhow inverse optimal control (IOC) can be used to learn behaviors from\\ndemonstrations, with applications to torque control of high-dimensional robotic\\nsystems. Our method addresses two key challenges in inverse optimal control:\\nfirst, the need for informative features and effective regularization to impose\\nstructure on the cost, and second, the difficulty of learning the cost function\\nunder unknown dynamics for high-dimensional continuous systems. To address the\\nformer challenge, we present an algorithm capable of learning arbitrary\\nnonlinear cost functions, such as neural networks, without meticulous feature\\nengineering. To address the latter challenge, we formulate an efficient\\nsample-based approximation for MaxEnt IOC. We evaluate our method on a series\\nof simulated tasks and real-world robotic manipulation problems, demonstrating\\nsubstantial improvement over prior methods both in terms of task complexity and\\nsample efficiency.\\n\\nPublished: 2017-03-13\\nTitle: Deep Visual Foresight for Planning Robot Motion\\nAuthors: Chelsea Finn, Sergey Levine\\nSummary: A key challenge in scaling up robot learning to many skills and environments\\nis removing the need for human supervision, so that robots can collect their\\nown data and improve their own performance without being limited by the cost of\\nrequesting human feedback. Model-based reinforcement learning holds the promise\\nof enabling an agent to learn to predict the effects of its actions, which\\ncould provide flexible predictive models for a wide range of tasks and\\nenvironments, without detailed human supervision. We develop a method for\\ncombining deep action-conditioned video prediction models with model-predictive\\ncontrol that uses entirely unlabeled training data. Our approach does not\\nrequire a calibrated camera, an instrumented training set-up, nor precise\\nsensing and actuation. Our results show that our method enables a real robot to\\nperform nonprehensile manipulation -- pushing objects -- and can handle novel\\nobjects not seen during training.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = arxiv.run(\"Chelsea Finn\")\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
