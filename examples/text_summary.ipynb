{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/langchain/blob/main/examples/text_summarization.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/jovyan/langchain/data/sample.txt\"\n",
    "\n",
    "\n",
    "#  データの用意\n",
    "with open(file_path) as f:\n",
    "    dragonball_txt = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(dragonball_txt)\n",
    "\n",
    "docs = [Document(page_content=t) for t in texts[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model_name=\"text-davinci-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff\n",
    "* 全ての関連データをコンテキストとしてプロンプトに詰め込み，言語モデルに渡す手法\n",
    "    * メリット：LLMへの呼び出しは一回のみになり，テキスト生成時にLLMは一度に全てのデータを参照できる\n",
    "    * デメリット：LLMのコンテキストの長さによる制限により大きなデータでは機能しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff53c7e350>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Kaggle is a company that hosts competitions for data scientists to build models that solve problems. The company has a large number of employees who are passionate about data analysis.\n",
      "\n",
      "The Kaggle Meet up is an event that was organized for employees to interact with each other and learn more about the company. The event was held both offline and online to accommodate for different preferences.\n",
      "\n",
      "Despite the bad weather, approximately 30 people attended the offline event, and around 90 people attended the online event. The event was a success, with employees and new graduates enjoying the talks and networking with each other.\n"
     ]
    }
   ],
   "source": [
    "# stuffのload_summarize_chainを準備\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# 要約の実行\n",
    "print(chain.run(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Reduce\n",
    "* 関連データをチャンクに分割し，チャンクごとにプロンプトを作り言語モデルに渡す．その後，それらの結果を結合するプロンプトを言語モデルに渡す\n",
    "    * メリット：Stuffingより大きなデータが扱える．チャンクのLLMの呼び出しを並列実行できる．\n",
    "    * デメリット：Stuffingより多くの回数のLLMの呼び出しが必要になる．また最後の結合により一部のデータを失う.チャットモデルではまだ対応していない\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff53c7e2c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Kaggle is a company that hosts competitions for data scientists to build the best machine learning models to solve real-world problems. Kaggle has over 200 data scientists on staff, and many more Kaggle users who are passionate about data analysis.\n",
      "\n",
      "The Kaggle Meet up is an event for employees to learn more about Kaggle and data science competitions. The event was held both offline and online to accommodate different interests and schedules.\n",
      "\n",
      "Despite the bad weather, approximately 30 people gathered in the seminar room, and 90 employees total participated in the event online, including new graduates. Some participants came from customer sites to the headquarters office, looking forward to the networking event.\n",
      "\n",
      "The event started with a series of lightning talks by 4 people with a wide range of Kaggle experience, from 1 year to Kaggle master. Topics included motivations for participating in Kaggle, how to choose competitions, results, how to approach Kaggle, what was gained from participation, and struggles. There was plenty of laughter and questions from the audience after the talks.\n",
      "\n",
      "The second half of the event was a networking event with pizza and drinks. Everyone was getting along well.\n"
     ]
    }
   ],
   "source": [
    "# map_reduceのload_summarize_chainを準備\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "# 要約の実行\n",
    "print(chain.run(docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
