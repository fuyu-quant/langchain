{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A about the document with source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/langchain/blob/main/examples/QA_for_document_with_source.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install faiss-cpu\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/jovyan/langchain/data/sample.txt\"\n",
    "\n",
    "\n",
    "#  データの用意\n",
    "with open(file_path) as f:\n",
    "    dragonball_txt = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(dragonball_txt)\n",
    "\n",
    "\n",
    "query = \"Kaggle社内Meet upとはどんなものですか?\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = FAISS.from_texts(\n",
    "    texts, \n",
    "    embeddings,\n",
    "    metadatas=[{\"source\": i} for i in range(len(texts))])\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff60aae200>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': ' Kaggle社内Meet upとは、Kaggleに参加したことがある社員や参加したことがないけれど興味がある社員、Kaggleに限らず技術コンペについて情報収集したい社員が、交流できるように企画されたイベントです。オフラインとオンラインの同時開催で、Kaggleに参加する動機や参加するコンペの選択方法、戦績、Kaggleの取り組み方などを発表し、懇親会を行うイベントです。\\nSOURCES: 0, 1, 2, 3'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "\n",
    "# ソース付きの質問応答の実行\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle社内Meet upとは？\n",
      "「Kaggle」については、ご存知の方も多いと思いますが、企業や組織・団体から投稿された課題とデータをもとに、解決に適した機械学習のモデルを構築して精度を競い合うコンペ式のサービスを言います。\n",
      "当社にはデータサイエンティストが約200名在籍していることもあり、データ分析の技術を研鑽するため、プライベートでKaggleに親しむKagglerが数多く在籍しています。\n",
      "\n",
      "今回のMeet upは、「Kaggleに参加したことがある」「参加したことはないけれど興味がある」「Kaggleに限らず技術コンペについて情報収集したい」という社員同志が、交流できるように企画されたイベントです！\n",
      "\n",
      "オフラインとオンラインの同時開催\n",
      "感染症対策の考慮もしつつ、当日は本社オフィスの広い会場（セミナールーム）にて、オフラインとオンライン、どちらでも参加可能なハイブリッド形式で開催されました。\n",
      "悪天候にも関わらずセミナールームには約30名が集合し、オンラインでは社員の他に新卒の内定者も加わって、総勢90名が参加する大きなイベントとなりました。\n",
      "中には、懇親会を楽しみに、お客様先などから本社オフィスへ移動してくる参加者もいました。\n",
      "\n",
      "当日のコンテンツ\n",
      "前半は、Kaggle歴1年目からKaggle master（！）まで幅広い経歴の4名によるライトニングトークが行われました。\n",
      "\n",
      "Kaggleに参加する動機、参加するコンペの選択方法、戦績、Kaggleの取り組み方、参加して得られたこと、苦しみ…など、幅広い話題が思い思いの形で発表され、笑いが起きる場面もしばしば。発表後には様々な質疑が飛び交いました。\n",
      "\n",
      "後半は、ピザなどの軽食とドリンクなどを囲み、懇親会が開催されました。皆さん、和気あいあいと打ち解けていました。\n",
      "\n",
      "\n",
      "参加者の感想\n",
      "普段あまりKaggleの活動について話す機会がないため、とても充実した時間を過ごすことができた。\n",
      "楽しそうに取り組んでいる様子が伝わってきて自分のモチベーションにもつながった。\n",
      "まだKaggleに取り組んだことがなく、コンペの選び方などがさっぱり分からなかったので、ライトニングトークが非常に参考になった。\n",
      "お客様への報告資料のようにまとめられていたところが、ブレインパッドっぽくて面白かったです。\n",
      "\n",
      "などなど…。これらの感想のとおり、「とっても有意義だったー」という雰囲気が伝われば嬉しいです。\n",
      "\n",
      "まとめ\n",
      "Kaggleのような技術コンペへの参加動機は人それぞれですが、業務とプライベートとを切り替えながら、時間などを工夫してそれぞれ参加していることがよく分かりました。\n",
      "また、在宅勤務と出社を併用できるフレキシブルな働き方に変わってきたからこそ、普段の業務で関わりのない人とのコミュニケーション機会が大切になってきていることを感じる会でした。\n",
      "主催者の皆様、企画ありがとうございました！！\n",
      "\n",
      "最後に\n",
      "Kaggle以外にも、当社では様々なナレッジ共有が日々行われています。\n",
      "・データ分析のナレッジ配信「OpenBrainPad Project」\n",
      "\n",
      "・有志のデータサイエンティストで運営しているPodcast「白金鉱業.FM」\n",
      "\n",
      "・プロジェクト紹介サイト「+AI」\n",
      "\n",
      "\n",
      "また当社では積極的に採用活動を行っています。\n",
      "ご興味をお持ちいただきましたら、ぜひ採用サイトからエントリ―をお願いいたします！\n"
     ]
    }
   ],
   "source": [
    "# 参照したソースの表示\n",
    "print(texts[0])\n",
    "print(texts[1])\n",
    "print(texts[2])\n",
    "print(texts[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
